# IBM_AIFairness360

An AI/ML decision making system can be biased towards certain individual or between certain groups. A biased AI/ML decision making system might not always fall under legal boundaries, but it might fall under the ethical boundaries which may lead to mistrust in the organization. The AIF360 is a comprehensive, open-source toolkit consisting of over 70 fairness metrics and over 10 bias mitigation algorithms. The toolkit does many jobs from detecting bias, understanding bias to mitigating bias through various algorithms.
